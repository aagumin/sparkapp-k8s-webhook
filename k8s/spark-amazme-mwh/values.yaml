# Default values for spark-amazme-mwh.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: asm-webhook
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: 0.44

imagePullSecrets: [ ]
nameOverride: ""
fullnameOverride: ""
podAnnotations: { }
podSecurityContext: { }
# fsGroup: 2000

securityContext:
  readOnlyRootFilesystem: true
  runAsNonRoot: true
  runAsUser: 10001

service:
  type: ClusterIP
  port: "9443"
  protocol: https

readinessProbePath: /health
livenessProbePath: /health

resources:
  limits:
    cpu: "2"
    memory: 4Gi
  requests:
    cpu: "2"
    memory: 2Gi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  targetMemoryUtilizationPercentage: 80

nodeSelector: { }

tolerations: [ ]

affinity: { }

mutate:
  mutateUrl: "/mutate"
  apiGroups:
    - "*"
  apiVersions:
    - "*"
  operations:
    - CREATE
  resources:
    - SparkApplication
    - SparkApplications
    - sparkapplications
    - sparkapplication
    - sparkapp
    - sparkapplications.sparkoperator.k8s.io
    - scheduledsparkapplications.sparkoperator.k8s.io
  scope: Namespaced
  sideEffects: None
  timeoutSeconds: 20
  objectSelector:
    matchExpressions:
      - key: deploymentApiType
        operator: NotIn
        values: ["nrt_job"]
      - key: amazme.webhook.status
        operator: NotIn
        values: ["disable"]


appConfig:
  spark:
    configMapName: asmwebhook-configmap
    configMapValue: ""

containerEnv:
  - name: LOG_LEVEL
    value: INFO
  - name: SPARK_CFG_PATH
    value: /etc/configs/spark.yaml

serviceAccount:
  create: false
  annotations: { }

rbac:
  createRole: false

metrics:
  # -- Enable prometheus metric scraping
  enable: false
  # -- Metrics port
  port: 10254
  # -- Metrics port name
  portName: metrics
  # -- Metrics serving endpoint
  endpoint: /metrics
  # -- Metric prefix, will be added to all exported metrics
  prefix: ""

# -- Prometheus pod monitor for operator's pod.
podMonitor:
  # -- If enabled, a pod monitor for operator's pod will be submitted. Note that prometheus metrics should be enabled as well.
  enable: false
  # -- Pod monitor labels
  labels: { }
  # -- The label to use to retrieve the job name from
  jobLabel: spark-operator-podmonitor
  # -- Prometheus metrics endpoint properties. `metrics.portName` will be used as a port
  podMetricsEndpoint:
    scheme: http
    interval: 5s
